{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5559f4c-6651-41d2-baf9-b1485cbb0afb",
   "metadata": {},
   "source": [
    "# CST3170 Coursework - AI Model Development\n",
    "\n",
    "By: Aman Mishra\n",
    "MISIS: M00983641\n",
    "Professor: Dr. Maha Saadeh\n",
    "\n",
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24ad75db-cf58-43f3-a868-c6165a53031d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d430d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set h (number of hidden neurons)\n",
    "h = 64  # Number of hidden neurons (can be modified)\n",
    "\n",
    "# Global arrays for outputs\n",
    "outputHidden = np.zeros(h)  # Hidden layer outputs\n",
    "outputneuron = np.zeros(10)  # Output layer outputs\n",
    "\n",
    "# Initialize random weights for the input-hidden and hidden-output connections\n",
    "WH = np.random.uniform(-1, 1, (h, 64))  # Weights between input and hidden layer\n",
    "WO = np.random.uniform(-1, 1, (10, h))  # Weights between hidden and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d3d0805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Feedforward method to calculate outputs\n",
    "def feedforward(dataSample):\n",
    "    global outputHidden, outputneuron\n",
    "\n",
    "    # Compute the output of the hidden neurons\n",
    "    for i in range(h):\n",
    "        weighted_sum_hidden = np.dot(dataSample, WH[i])  # Weighted sum for hidden neuron i\n",
    "        outputHidden[i] = sigmoid(weighted_sum_hidden)  # Apply sigmoid\n",
    "\n",
    "    # Compute the output of the output neurons\n",
    "    for i in range(10):\n",
    "        weighted_sum_output = np.dot(outputHidden, WO[i])  # Weighted sum for output neuron i\n",
    "        outputneuron[i] = 1 if weighted_sum_output >= 0 else 0  # Apply threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a20ef01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test error method to compare outputneuron with Map\n",
    "def testError(Map):\n",
    "    for i in range(10):\n",
    "        if Map[i] != outputneuron[i]:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Training method to adjust weights based on the errors\n",
    "def training(Map, dataSample, learningRate=0.0125):\n",
    "    global WH, WO\n",
    "\n",
    "    # Compute error for the output neurons\n",
    "    errorOutput = np.zeros(10)  # Error for the output neurons\n",
    "    for i in range(10):\n",
    "        errorOutput[i] = Map[i] - outputneuron[i]\n",
    "\n",
    "    # Compute error for the hidden neurons\n",
    "    errorHidden = np.zeros(h)  # Error for the hidden neurons\n",
    "    for j in range(h):\n",
    "        errorTemp = 0\n",
    "        for i in range(10):\n",
    "            errorTemp += errorOutput[i] * WO[i][j]\n",
    "        errorHidden[j] = outputHidden[j] * (1 - outputHidden[j]) * errorTemp\n",
    "\n",
    "    # Adjust weights between hidden and output neurons (WO)\n",
    "    for i in range(10):  # Loop over output neurons\n",
    "        for j in range(h):  # Loop over hidden neurons\n",
    "            WO[i][j] += learningRate * outputHidden[j] * errorOutput[i]\n",
    "\n",
    "    # Adjust weights between input and hidden neurons (WH)\n",
    "    for i in range(h):  # Loop over hidden neurons\n",
    "        for j in range(64):  # Loop over input data sample\n",
    "            WH[i][j] += learningRate * dataSample[j] * errorHidden[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2b09176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from CSV\n",
    "training_data_path = 'cw2DataSet1.csv'  # Ensure this is the correct path\n",
    "training_data = pd.read_csv(training_data_path)\n",
    "\n",
    "# Set learning rate and number of cycles\n",
    "learningRate = 0.0125\n",
    "total_cycles = 500  # Total number of training cycles\n",
    "display_interval = 5  # Display accuracy after every 50 cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d340662a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate through the cycles\n",
    "for cycle in range(total_cycles):\n",
    "    success = 0\n",
    "    total_rows = len(training_data)\n",
    "\n",
    "    # Process each data sample\n",
    "    for _, row in training_data.iterrows():\n",
    "        dataSample = row[:-1].values  # First 64 columns as dataSample\n",
    "        targetOutput = int(row.iloc[-1])  # Last column as targetOutput using iloc\n",
    "\n",
    "        # Initialize the Map array to zeros\n",
    "        Map = np.zeros(10)\n",
    "        Map[targetOutput] = 1  # Set the target output index to 1\n",
    "\n",
    "        # Feedforward\n",
    "        feedforward(dataSample)\n",
    "\n",
    "        # Test error and update weights if needed\n",
    "        if testError(Map):\n",
    "            training(Map, dataSample, learningRate)\n",
    "        else:\n",
    "            success += 1\n",
    "\n",
    "    # Calculate accuracy at the end of each cycle\n",
    "    accuracy = success / total_rows\n",
    "\n",
    "    # Display the accuracy after every 50 cycles\n",
    "    if (cycle + 1) % display_interval == 0:\n",
    "        print(f\"Cycle {cycle + 1}, Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
